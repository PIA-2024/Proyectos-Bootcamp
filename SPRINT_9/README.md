# üè¶ Predicci√≥n de Abandono de Clientes en un Banco con Aprendizaje Supervisado

# üìñ Resumen del Proyecto
El objetivo de este proyecto es predecir si un cliente o una clienta abandonar√° el banco en el corto plazo, permitiendo a la empresa financiera desarrollar estrategias de retenci√≥n.

Para lograrlo, se entrenaron modelos de clasificaci√≥n supervisada, explorando t√©cnicas avanzadas de codificaci√≥n de variables, escalado, manejo del desbalance de clases y evaluaci√≥n con m√©tricas m√∫ltiples.

El rendimiento del modelo se evaluar√° con F1-score, AUC-ROC y otras m√©tricas para determinar el mejor enfoque.

# üõ† Metodolog√≠a Utilizada
El proyecto sigue un enfoque estructurado de machine learning:

# üîç 1. Exploraci√≥n y An√°lisis de Datos (EDA)
Carga del conjunto de datos con informaci√≥n sobre clientes del banco.
Revisi√≥n de la estructura del dataset, tipos de variables y distribuci√≥n de datos.
Identificaci√≥n de valores nulos y tratamiento de datos inconsistentes.
An√°lisis de correlaciones entre variables y la variable objetivo (abandono del banco: S√≠ / No).
Evaluaci√≥n del desbalance de clases y estrategias para abordarlo.

# üèóÔ∏è 2. Preprocesamiento de Datos
Conversi√≥n de datos categ√≥ricos mediante One-Hot Encoding y Label Encoding.
Normalizaci√≥n de variables num√©ricas con StandardScaler o MinMaxScaler.
Manejo del desbalance de clases con t√©cnicas como undersampling, oversampling y SMOTE.
Divisi√≥n del dataset en conjunto de entrenamiento (80%) y prueba (20%).

# ü§ñ 3. Entrenamiento de Modelos de Machine Learning
Se probaron distintos modelos de clasificaci√≥n, incluyendo:

Regresi√≥n Log√≠stica ‚Üí Modelo base para evaluar el rendimiento inicial.
√Årboles de Decisi√≥n ‚Üí Para capturar relaciones no lineales en los datos.
Random Forest ‚Üí Modelo basado en ensambles para mejorar la predicci√≥n.
Gradient Boosting (XGBoost, LightGBM, CatBoost) ‚Üí Modelos avanzados para optimizaci√≥n de predicciones.
Se realiz√≥ tuneo de hiperpar√°metros mediante Grid Search y Random Search para mejorar la precisi√≥n del modelo.

# üéØ 4. Evaluaci√≥n del Modelo
Comparaci√≥n de modelos utilizando m√©tricas clave:
F1-score ‚Üí M√©trica principal para evaluar la clasificaci√≥n.
AUC-ROC ‚Üí Para medir la capacidad de diferenciaci√≥n del modelo.
Precisi√≥n y Recall ‚Üí Evaluaci√≥n del equilibrio entre falsos positivos y negativos.
Matriz de confusi√≥n para visualizar errores de clasificaci√≥n.

# üìö Librer√≠as Utilizadas
Para la implementaci√≥n del modelo, se usaron las siguientes librer√≠as en Python:

Pandas / NumPy ‚Üí Manipulaci√≥n y an√°lisis de datos.
Matplotlib / Seaborn ‚Üí Visualizaci√≥n de datos.
Scikit-learn ‚Üí Modelos de clasificaci√≥n, m√©tricas y optimizaci√≥n.
Imbalanced-learn ‚Üí Manejo del desbalance de clases con SMOTE.
XGBoost / LightGBM / CatBoost ‚Üí Algoritmos avanzados de boosting para mejorar la clasificaci√≥n.

# üìà Resultados y Conclusi√≥n
El modelo de Gradient Boosting (XGBoost) logr√≥ el mejor rendimiento, alcanzando un F1-score alto y un AUC-ROC superior a 0.85, lo que indica una excelente capacidad de predicci√≥n.
Las variables m√°s influyentes en la predicci√≥n del abandono fueron:
Saldo promedio del cliente.
N√∫mero de productos contratados.
Tiempo de antig√ºedad en el banco.
Tipo de cuenta y regi√≥n del cliente.
El manejo del desbalance de clases con SMOTE mejor√≥ la capacidad predictiva del modelo, reduciendo falsos negativos.
Se recomienda implementar estrategias de retenci√≥n para los clientes con alta probabilidad de abandonar, como mejoras en el servicio y ofertas personalizadas.
