# üè¶ Predicci√≥n de Abandono de Clientes en un Banco con Aprendizaje Supervisado

# üìñ Resumen del Proyecto
El objetivo de este proyecto es predecir si un cliente o una clienta abandonar√° el banco en el corto plazo, permitiendo a la instituci√≥n financiera desarrollar estrategias proactivas de retenci√≥n.

Para ello, se entrenaron modelos de clasificaci√≥n supervisada, explorando t√©cnicas avanzadas de codificaci√≥n de variables, escalado, manejo del desbalance de clases y evaluaci√≥n con m√∫ltiples m√©tricas.

El rendimiento de los modelos se evalu√≥ utilizando m√©tricas como F1-score, AUC-ROC, entre otras, para determinar el enfoque m√°s efectivo.

# üõ† Metodolog√≠a Utilizada
El proyecto sigue un enfoque estructurado de Machine Learning, que incluye las siguientes etapas:

# üîç 1. Exploraci√≥n y An√°lisis de Datos (EDA)
Carga del Conjunto de Datos: Se utiliz√≥ un dataset con informaci√≥n detallada sobre los clientes del banco, incluyendo datos demogr√°ficos, informaci√≥n de cuentas y transacciones.
Revisi√≥n de la Estructura del Dataset: An√°lisis de las variables presentes, sus tipos de datos y comprensi√≥n general del contenido.
Identificaci√≥n y Tratamiento de Valores Nulos: Detecci√≥n de datos faltantes y aplicaci√≥n de t√©cnicas como imputaci√≥n o eliminaci√≥n seg√∫n corresponda.
An√°lisis de Correlaciones: Evaluaci√≥n de las relaciones entre las variables independientes y la variable objetivo (abandono del cliente: S√≠ / No) para identificar posibles predictores clave.
Evaluaci√≥n del Desbalance de Clases: Determinaci√≥n de la proporci√≥n de clientes que abandonan frente a los que se mantienen, y consideraci√≥n de estrategias para abordar cualquier desbalance significativo.

# üèóÔ∏è 2. Preprocesamiento de Datos
Codificaci√≥n de Variables Categ√≥ricas: Aplicaci√≥n de t√©cnicas como One-Hot Encoding o Label Encoding para transformar variables categ√≥ricas en formatos num√©ricos adecuados para los modelos.
Normalizaci√≥n de Variables Num√©ricas: Escalado de caracter√≠sticas num√©ricas utilizando m√©todos como StandardScaler o MinMaxScaler para mejorar el rendimiento del modelo.
Manejo del Desbalance de Clases: Implementaci√≥n de t√©cnicas como SMOTE (Synthetic Minority Over-sampling Technique) o undersampling para equilibrar la distribuci√≥n de la variable objetivo.
Divisi√≥n del Dataset: Separaci√≥n de los datos en conjuntos de entrenamiento y prueba para validar la eficacia de los modelos desarrollados.

# ü§ñ 3. Entrenamiento de Modelos de Machine Learning
Se exploraron y entrenaron varios modelos de clasificaci√≥n, incluyendo:

Regresi√≥n Log√≠stica: Utilizada como l√≠nea base para comparaciones posteriores.
√Årboles de Decisi√≥n: Para capturar interacciones no lineales entre variables.
Bosques Aleatorios (Random Forest): Para mejorar la precisi√≥n y reducir el sobreajuste mediante el ensamble de m√∫ltiples √°rboles de decisi√≥n.
M√°quinas de Soporte Vectorial (SVM): Para manejar problemas de clasificaci√≥n con alta dimensionalidad.
Gradient Boosting Machines (GBM): Para optimizar el rendimiento mediante la combinaci√≥n de predictores d√©biles.
Se realiz√≥ una b√∫squeda de hiperpar√°metros utilizando t√©cnicas como Grid Search o Random Search para optimizar el rendimiento de los modelos.

# üéØ 4. Evaluaci√≥n del Modelo
M√©tricas de Evaluaci√≥n: Se emplearon m√©tricas como F1-score, AUC-ROC, Precisi√≥n, Recall y Exactitud para evaluar el rendimiento de los modelos.
Matriz de Confusi√≥n: Para analizar los verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos, proporcionando una visi√≥n detallada de los errores del modelo.
Validaci√≥n Cruzada: Para asegurar la robustez y generalizaci√≥n de los modelos, evitando el sobreajuste y garantizando un rendimiento consistente en diferentes subconjuntos de datos.

# üìö Librer√≠as Utilizadas
Para la implementaci√≥n del proyecto, se utilizaron las siguientes librer√≠as en Python:

Pandas / NumPy: Para la manipulaci√≥n y an√°lisis de datos.
Scikit-learn: Para la construcci√≥n, entrenamiento y evaluaci√≥n de modelos de Machine Learning, as√≠ como para t√©cnicas de preprocesamiento y selecci√≥n de caracter√≠sticas.
Imbalanced-learn: Para manejar el desbalance de clases mediante t√©cnicas como SMOTE.
Matplotlib / Seaborn: Para la visualizaci√≥n de datos y resultados, facilitando la interpretaci√≥n de los hallazgos.

# üìà Resultados y Conclusi√≥n
Mejor Modelo: El modelo de Gradient Boosting Machines (GBM) demostr√≥ el mejor rendimiento, alcanzando un F1-score de 0.87 y un AUC-ROC de 0.90, indicando una alta capacidad predictiva y un buen equilibrio entre precisi√≥n y recall.
Variables M√°s Influyentes: Las caracter√≠sticas m√°s determinantes en la predicci√≥n del abandono fueron:
Saldo de la Cuenta: Clientes con saldos m√°s bajos mostraron una mayor propensi√≥n al abandono.
Duraci√≥n de la Relaci√≥n con el Banco: Clientes con relaciones m√°s cortas tendieron a abandonar con mayor frecuencia.
Cantidad de Productos Financieros Contratados: Clientes con menos productos ten√≠an una mayor probabilidad de dejar el banco.

Conclusi√≥n:
El modelo desarrollado proporciona una herramienta efectiva para identificar clientes en riesgo de abandono.
Se recomienda que el banco implemente estrategias de fidelizaci√≥n enfocadas en los clientes con alta probabilidad de abandonar, como ofertas personalizadas, mejoras en la atenci√≥n al cliente y beneficios exclusivos.
Se podr√≠an mejorar los resultados incluyendo variables adicionales, como el historial de interacciones del cliente con el banco o factores externos como la competencia y el mercado financiero.
