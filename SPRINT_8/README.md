# üì° Clasificaci√≥n de Clientes para Planes de Megaline

# üìñ Resumen del Proyecto
Megaline, una compa√±√≠a de telefon√≠a m√≥vil, quiere optimizar la migraci√≥n de sus clientes hacia nuevos planes tarifarios. Actualmente, muchos usuarios siguen usando planes heredados, lo que genera un desaf√≠o en la adopci√≥n de los planes Smart y Ultra.

Este proyecto tiene como objetivo desarrollar un modelo de clasificaci√≥n que, basado en el comportamiento de los clientes, recomiende el plan m√°s adecuado.

El modelo se evaluar√° utilizando la m√©trica de exactitud (accuracy) y debe alcanzar un m√≠nimo de 0.75 para ser considerado satisfactorio.

# üõ† Metodolog√≠a Utilizada
El proyecto sigue una serie de pasos clave en el desarrollo de modelos de clasificaci√≥n:

# üîç 1. Exploraci√≥n y An√°lisis de Datos (EDA)
Carga del dataset con informaci√≥n del uso de servicios por los clientes.
An√°lisis de la distribuci√≥n de variables num√©ricas y categ√≥ricas.
Identificaci√≥n de valores nulos y estrategia de imputaci√≥n.
An√°lisis de correlaci√≥n entre variables y la variable objetivo (Plan: Smart o Ultra).

# üèóÔ∏è 2. Preprocesamiento de Datos
Conversi√≥n de datos categ√≥ricos mediante One-Hot Encoding o Label Encoding.
Normalizaci√≥n de variables num√©ricas para mejorar la eficiencia del modelo.
Separaci√≥n del dataset en conjunto de entrenamiento (80%) y prueba (20%).

# ü§ñ 3. Entrenamiento de Modelos de Machine Learning
Se probaron varios algoritmos de clasificaci√≥n para determinar cu√°l ofrece el mejor rendimiento:

Regresi√≥n Log√≠stica ‚Üí Modelo base para evaluar desempe√±o inicial.
√Årboles de Decisi√≥n ‚Üí Para capturar relaciones no lineales en los datos.
Random Forest ‚Üí Modelo basado en ensambles para mejorar la clasificaci√≥n.
Gradient Boosting (XGBoost, LightGBM) ‚Üí Modelos avanzados que optimizan predicciones.

# üéØ 4. Evaluaci√≥n del Modelo
Comparaci√≥n de modelos utilizando m√©tricas de clasificaci√≥n:
Exactitud (accuracy) ‚Üí M√©trica principal, debe ser ‚â• 0.75.
Matriz de confusi√≥n para analizar falsos positivos y negativos.
Precisi√≥n, Recall y F1-score para evaluar balance en la clasificaci√≥n.
Ajuste de hiperpar√°metros mediante Grid Search o Random Search para mejorar la exactitud.

# üìö Librer√≠as Utilizadas
Para el desarrollo del modelo, se emplearon las siguientes librer√≠as en Python:

Pandas / NumPy ‚Üí Manipulaci√≥n y an√°lisis de datos.
Matplotlib / Seaborn ‚Üí Visualizaci√≥n de datos.
Scikit-learn ‚Üí Modelos de clasificaci√≥n, m√©tricas y optimizaci√≥n.
XGBoost / LightGBM ‚Üí Algoritmos avanzados de boosting para mejorar la predicci√≥n.

# üìà Resultados y Conclusi√≥n
El modelo de Random Forest alcanz√≥ una exactitud superior al 75%, cumpliendo con los requisitos del proyecto.
Las caracter√≠sticas m√°s importantes en la predicci√≥n fueron:
Duraci√≥n de llamadas y cantidad de SMS enviados.
Uso de datos m√≥viles en GB.
Historial de facturaci√≥n y pagos.
El modelo puede ser utilizado para recomendar autom√°ticamente planes a nuevos clientes, optimizando la retenci√≥n y migraci√≥n de usuarios.
Se recomienda seguir refinando el modelo con t√©cnicas de aprendizaje profundo o sistemas de recomendaci√≥n basados en aprendizaje autom√°tico.
