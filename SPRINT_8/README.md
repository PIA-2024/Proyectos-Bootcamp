# üì± Clasificaci√≥n de Clientes para Planes Tarifarios de Megaline

# üìñ Resumen del Proyecto
La empresa de telecomunicaciones Megaline busca optimizar la migraci√≥n de sus clientes desde planes heredados hacia sus nuevos planes tarifarios: Smart y Ultra.

El objetivo de este proyecto es desarrollar un modelo de clasificaci√≥n supervisada que, basado en el comportamiento y caracter√≠sticas de los clientes, recomiende el plan m√°s adecuado para cada usuario.

El modelo se evaluar√° utilizando la m√©trica de exactitud (accuracy), con un umbral m√≠nimo de 0.75 para ser considerado satisfactorio.

# üõ† Metodolog√≠a Utilizada
El desarrollo del proyecto se estructur√≥ en las siguientes etapas:

# üîç 1. Exploraci√≥n y An√°lisis de Datos (EDA)
Carga del Dataset: Se recopil√≥ informaci√≥n detallada sobre el uso de servicios por parte de los clientes, incluyendo datos como la cantidad de minutos de llamadas, mensajes de texto enviados y volumen de datos utilizados.
An√°lisis Descriptivo: Se evalu√≥ la distribuci√≥n de variables num√©ricas y categ√≥ricas para comprender el comportamiento general de los clientes.
Detecci√≥n de Valores Nulos: Se identificaron y analizaron valores faltantes, determinando estrategias de imputaci√≥n o eliminaci√≥n seg√∫n corresponda.
An√°lisis de Correlaci√≥n: Se investigaron las relaciones entre las variables independientes y la variable objetivo (plan tarifario: Smart o Ultra) para identificar posibles predictores clave.

# üèóÔ∏è 2. Preprocesamiento de Datos
Codificaci√≥n de Variables Categ√≥ricas: Se aplicaron t√©cnicas como One-Hot Encoding o Label Encoding para transformar variables categ√≥ricas en formatos num√©ricos adecuados para los modelos de Machine Learning.
Normalizaci√≥n de Variables Num√©ricas: Se realiz√≥ el escalado de caracter√≠sticas num√©ricas utilizando m√©todos como StandardScaler o MinMaxScaler para mejorar el rendimiento y la convergencia de los modelos.
Divisi√≥n del Dataset: Se separaron los datos en conjuntos de entrenamiento y prueba para validar la eficacia de los modelos desarrollados.

# ü§ñ 3. Entrenamiento de Modelos de Machine Learning
Se exploraron y entrenaron varios modelos de clasificaci√≥n, incluyendo:

Regresi√≥n Log√≠stica: Utilizada como l√≠nea base para comparaciones posteriores.
√Årboles de Decisi√≥n: Para capturar interacciones no lineales entre variables y facilitar la interpretaci√≥n de los resultados.
Bosques Aleatorios (Random Forest): Para mejorar la precisi√≥n y reducir el sobreajuste mediante el ensamble de m√∫ltiples √°rboles de decisi√≥n.
M√°quinas de Soporte Vectorial (SVM): Para manejar problemas de clasificaci√≥n con alta dimensionalidad y encontrar el hiperplano √≥ptimo que separa las clases.
Gradient Boosting (XGBoost / LightGBM): Modelos avanzados de boosting para optimizar las predicciones.
Se realiz√≥ una b√∫squeda de hiperpar√°metros utilizando t√©cnicas como Grid Search o Random Search para optimizar el rendimiento de los modelos.

# üéØ 4. Evaluaci√≥n del Modelo
M√©tricas de Evaluaci√≥n: Se emplearon m√©tricas como Exactitud (Accuracy), Precisi√≥n, Recall y F1-Score para evaluar el rendimiento de los modelos.
Matriz de Confusi√≥n: Para analizar los verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos, proporcionando una visi√≥n detallada de los errores del modelo.
Validaci√≥n Cruzada: Para asegurar la robustez y generalizaci√≥n de los modelos, evitando el sobreajuste y garantizando un rendimiento consistente en diferentes subconjuntos de datos.

# üìö Librer√≠as Utilizadas
Para la implementaci√≥n del proyecto, se utilizaron las siguientes librer√≠as en Python:

Pandas / NumPy: Para la manipulaci√≥n y an√°lisis de datos.
Scikit-learn: Para la construcci√≥n, entrenamiento y evaluaci√≥n de modelos de Machine Learning, as√≠ como para t√©cnicas de preprocesamiento y selecci√≥n de caracter√≠sticas.
Matplotlib / Seaborn: Para la visualizaci√≥n de datos y resultados, facilitando la interpretaci√≥n de los hallazgos.
XGBoost / LightGBM: Modelos avanzados de boosting para optimizar la predicci√≥n de planes tarifarios.

# üìà Resultados y Conclusi√≥n
Mejor Modelo: El modelo de Bosques Aleatorios (Random Forest) demostr√≥ el mejor rendimiento, alcanzando una exactitud (accuracy) de 0.78, superando el umbral establecido de 0.75.
Variables M√°s Influyentes: Las caracter√≠sticas m√°s determinantes en la recomendaci√≥n del plan fueron:
Uso de Datos M√≥viles: Clientes con un alto consumo de datos tendieron a ser recomendados para el plan Ultra.
Cantidad de Minutos de Llamadas: Clientes con un uso intensivo de llamadas fueron m√°s propensos a ser recomendados para el plan Smart.
N√∫mero de Mensajes de Texto Enviados: Aunque con menor peso, tambi√©n influy√≥ en la recomendaci√≥n del plan adecuado.

Conclusi√≥n:
El modelo desarrollado proporciona una herramienta efectiva para recomendar planes tarifarios a los clientes de Megaline, bas√°ndose en su comportamiento de uso.
Se recomienda que la empresa implemente este modelo para guiar a los clientes en la selecci√≥n del plan que mejor se adapte a sus necesidades, lo que podr√≠a mejorar la satisfacci√≥n del cliente y optimizar el uso de los recursos de la red.
Para futuras mejoras, se podr√≠an probar modelos m√°s avanzados como redes neuronales o implementar sistemas de recomendaci√≥n h√≠bridos para personalizar a√∫n m√°s las recomendaciones.
