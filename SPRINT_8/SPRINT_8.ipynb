{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del proyecto\n",
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "Tienes acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos (del proyecto del sprint de Análisis estadístico de datos). Para esta tarea de clasificación debes crear un modelo que escoja el plan correcto. Como ya hiciste el paso de procesar los datos, puedes lanzarte directo a crear el modelo.\n",
    "Desarrolla un modelo con la mayor exactitud posible. En este proyecto, el umbral de exactitud es 0.75. Usa el dataset para comprobar la exactitud.\n",
    "Instrucciones del proyecto.\n",
    "## \tAbre y examina el archivo de datos. Dirección al archivo:datasets/users_behavior.csv Descarga el dataset\n",
    "## \tSegmenta los datos fuente en un conjunto de entrenamiento, uno de validación y uno de prueba.\n",
    "## \tInvestiga la calidad de diferentes modelos cambiando los hiperparámetros. Describe brevemente los hallazgos del estudio.\n",
    "## \tComprueba la calidad del modelo usando el conjunto de prueba.\n",
    "## \tTarea adicional: haz una prueba de cordura al modelo. Estos datos son más complejos que los que habías usado antes así que no será una tarea fácil. Más adelante lo veremos con más detalle.\n",
    "# Descripción de datos\n",
    "Cada observación en el dataset contiene información del comportamiento mensual sobre un usuario. La información dada es la siguiente:\n",
    "•\tсalls — número de llamadas,\n",
    "•\tminutes — duración total de la llamada en minutos,\n",
    "•\tmessages — número de mensajes de texto,\n",
    "•\tmb_used — Tráfico de Internet utilizado en MB,\n",
    "•\tis_ultra — plan para el mes actual (Ultra - 1, Smart - 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1: Cargar y examinar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   calls  minutes  messages   mb_used  is_ultra\n",
       " 0   40.0   311.90      83.0  19915.42         0\n",
       " 1   85.0   516.75      56.0  22696.96         0\n",
       " 2   77.0   467.66      86.0  21060.45         0\n",
       " 3  106.0   745.53      81.0   8437.39         1\n",
       " 4   66.0   418.74       1.0  14502.75         0,\n",
       " None,\n",
       "              calls      minutes     messages       mb_used     is_ultra\n",
       " count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       " mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       " std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       " min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       " 25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       " 50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       " 75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       " max     244.000000  1632.060000   224.000000  49745.730000     1.000000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar los datos desde el archivo CSV\n",
    "data = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "# Mostrar las primeras filas del dataset y la información general\n",
    "data.head(), data.info(), data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 2: Segmentación de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (1928, 5)\n",
      "Tamaño del conjunto de validación: (643, 5)\n",
      "Tamaño del conjunto de prueba: (643, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Primero, dividimos los datos en entrenamiento y temporal (combinando validación y prueba)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.4, random_state=123)\n",
    "\n",
    "# Luego, dividimos los datos temporales en validación y prueba\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=123)\n",
    "\n",
    "# Imprimir las dimensiones de cada conjunto\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", train_data.shape)\n",
    "print(\"Tamaño del conjunto de validación:\", validation_data.shape)\n",
    "print(\"Tamaño del conjunto de prueba:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 3: Investigación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.7589424572317263,\n",
       " 'Decision Tree': 0.7465007776049767,\n",
       " 'Random Forest': 0.8180404354587869}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Preparar los conjuntos de datos\n",
    "features_train = train_data.drop(columns=['is_ultra'])\n",
    "target_train = train_data['is_ultra']\n",
    "features_validation = validation_data.drop(columns=['is_ultra'])\n",
    "target_validation = validation_data['is_ultra']\n",
    "\n",
    "# Modelos a evaluar\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=123, max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=123),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=123)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_validation)\n",
    "    accuracy = accuracy_score(target_validation, predictions)\n",
    "    results[name] = accuracy\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 4: Ajuste de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_depth': 10, 'n_estimators': 100}\n",
      "Mejor exactitud de cross-validation: 0.8034185549628639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir la cuadrícula de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None]\n",
    "}\n",
    "\n",
    "# Inicializar el modelo GridSearchCV con el modelo RandomForest y la cuadrícula de parámetros\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=123), param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Entrenar GridSearchCV en los datos de entrenamiento\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "# Obtener el mejor modelo y su puntuación\n",
    "best_model = grid_search.best_estimator_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "# Imprimir los mejores hiperparámetros y la mejor exactitud\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor exactitud de cross-validation:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 5: Evaluación Final en el Conjunto de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud en el conjunto de prueba: 0.7931570762052877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Preparar las características y la variable objetivo del conjunto de prueba\n",
    "features_test = test_data.drop(columns=['is_ultra'])\n",
    "target_test = test_data['is_ultra']\n",
    "\n",
    "# Utilizar el mejor modelo para hacer predicciones en el conjunto de prueba\n",
    "test_predictions = best_model.predict(features_test)\n",
    "\n",
    "# Calcular y mostrar la exactitud en el conjunto de prueba\n",
    "test_accuracy = accuracy_score(target_test, test_predictions)\n",
    "print(\"Exactitud en el conjunto de prueba:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de Cordura (Paso 5 Adicional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones para datos extremos: [1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Crear datos de entrada extremos\n",
    "extreme_data = pd.DataFrame({\n",
    "    'calls': [0, 300],  # Muy pocas llamadas y muchas llamadas\n",
    "    'minutes': [0, 2000],  # Ninguna duración y duración muy larga\n",
    "    'messages': [0, 500],  # Ningún mensaje y muchos mensajes\n",
    "    'mb_used': [0, 50000]  # Sin uso de datos y uso extremadamente alto\n",
    "})\n",
    "\n",
    "# Hacer predicciones con el mejor modelo\n",
    "extreme_predictions = best_model.predict(extreme_data)\n",
    "print(\"Predicciones para datos extremos:\", extreme_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importancia de las características: {'calls': 0.21865436174556474, 'minutes': 0.22983324249122952, 'messages': 0.21606859535819978, 'mb_used': 0.3354438004050059}\n"
     ]
    }
   ],
   "source": [
    "importances = best_model.feature_importances_\n",
    "features = ['calls', 'minutes', 'messages', 'mb_used']\n",
    "importance_dict = dict(zip(features, importances))\n",
    "\n",
    "print(\"Importancia de las características:\", importance_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones para Datos Extremos:\n",
    "\n",
    "El modelo predice \"1\" (plan Ultra) para ambos casos extremos (mínimos y máximos en uso de llamadas, minutos, mensajes y datos). Esto sugiere que el modelo podría estar sesgado hacia la clasificación de usuarios en el plan Ultra cuando se presentan valores extremos. Este comportamiento puede ser un área de interés para investigar más a fondo, especialmente en términos de cómo el balance de clases y la distribución de las características afectan el entrenamiento del modelo.\n",
    "\n",
    "Importancia de las Características:\n",
    "\n",
    "mb_used: 33.54% - Esta es la característica más influyente según el modelo, lo cual tiene sentido intuitivamente, ya que el uso de datos podría ser un buen indicador de la necesidad de un plan más robusto como el Ultra.\n",
    "minutes: 22.98% - La duración de las llamadas también es significativa, lo que es razonable dado que podría correlacionarse con un uso más intensivo del plan.\n",
    "calls: 21.87% - Similar a minutes, el número de llamadas también influye notablemente en la clasificación.\n",
    "messages: 21.61% - Aunque también es importante, tiene un poco menos de peso que las llamadas y los minutos, lo que podría reflejar una menor variabilidad en el número de mensajes entre los usuarios de diferentes planes o una menor relevancia de los mensajes en la decisión del plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 483,
    "start_time": "2024-06-30T14:52:46.059Z"
   },
   {
    "duration": 1191,
    "start_time": "2024-06-30T14:52:47.298Z"
   },
   {
    "duration": 485,
    "start_time": "2024-06-30T14:53:01.271Z"
   },
   {
    "duration": 1144,
    "start_time": "2024-06-30T14:53:01.759Z"
   },
   {
    "duration": 195,
    "start_time": "2024-06-30T14:53:55.559Z"
   },
   {
    "duration": 57,
    "start_time": "2024-06-30T14:55:38.679Z"
   },
   {
    "duration": 732,
    "start_time": "2024-06-30T14:56:08.619Z"
   },
   {
    "duration": 9,
    "start_time": "2024-06-30T14:56:16.381Z"
   },
   {
    "duration": 9,
    "start_time": "2024-06-30T14:58:02.299Z"
   },
   {
    "duration": 12,
    "start_time": "2024-06-30T14:59:00.879Z"
   },
   {
    "duration": 15,
    "start_time": "2024-06-30T15:02:24.091Z"
   },
   {
    "duration": 15,
    "start_time": "2024-06-30T15:04:00.418Z"
   },
   {
    "duration": 754,
    "start_time": "2024-06-30T15:06:56.959Z"
   },
   {
    "duration": 12975,
    "start_time": "2024-06-30T15:10:00.499Z"
   },
   {
    "duration": 615,
    "start_time": "2024-06-30T15:11:50.399Z"
   },
   {
    "duration": 13756,
    "start_time": "2024-06-30T15:14:50.316Z"
   },
   {
    "duration": 25,
    "start_time": "2024-06-30T15:17:35.552Z"
   },
   {
    "duration": 34,
    "start_time": "2024-06-30T15:22:22.935Z"
   },
   {
    "duration": 14,
    "start_time": "2024-06-30T15:22:24.199Z"
   },
   {
    "duration": 279,
    "start_time": "2024-09-01T15:26:03.933Z"
   },
   {
    "duration": 36,
    "start_time": "2024-09-01T15:26:04.298Z"
   },
   {
    "duration": 435,
    "start_time": "2024-09-01T15:26:05.417Z"
   },
   {
    "duration": 369,
    "start_time": "2024-09-01T15:26:06.094Z"
   },
   {
    "duration": 6830,
    "start_time": "2024-09-01T15:26:06.808Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-01T15:26:13.644Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-01T15:26:13.661Z"
   },
   {
    "duration": 9,
    "start_time": "2024-09-01T15:26:13.674Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
