# üöñ Predicci√≥n de Cancelaci√≥n de Clientes en Sweet Lift Taxi

# üìñ Resumen del Proyecto
El objetivo de este proyecto es predecir la cancelaci√≥n de clientes en la empresa de transporte Sweet Lift Taxi, permitiendo a la compa√±√≠a identificar patrones de abandono y desarrollar estrategias para mejorar la retenci√≥n de clientes.

Para lograr esto, se entrenaron modelos de clasificaci√≥n supervisada, utilizando datos demogr√°ficos y de comportamiento de los clientes. Se evalu√≥ el desempe√±o de los modelos utilizando m√©tricas como AUC-ROC y F1-score para determinar la mejor estrategia de predicci√≥n.

# üõ† Metodolog√≠a Utilizada
Para desarrollar este modelo de clasificaci√≥n, se siguieron los siguientes pasos:

# üîç 1. Exploraci√≥n y An√°lisis de Datos (EDA)
Carga del dataset con informaci√≥n sobre clientes de Sweet Lift Taxi.
Revisi√≥n de la estructura del dataset, tipos de variables y distribuci√≥n de datos.
Identificaci√≥n de valores nulos y tratamiento de datos inconsistentes.
An√°lisis de correlaciones entre variables y la variable objetivo (cancelaci√≥n del cliente: S√≠ / No).

# üèóÔ∏è 2. Preprocesamiento de Datos
Conversi√≥n de datos categ√≥ricos mediante One-Hot Encoding y Label Encoding.
Normalizaci√≥n de variables num√©ricas con StandardScaler o MinMaxScaler.
Manejo del desbalance de clases con t√©cnicas como undersampling, oversampling y SMOTE.
Divisi√≥n del dataset en conjunto de entrenamiento (80%) y prueba (20%).

# ü§ñ 3. Entrenamiento de Modelos de Machine Learning
Se probaron distintos modelos de clasificaci√≥n, incluyendo:

Regresi√≥n Log√≠stica ‚Üí Modelo base para evaluar el rendimiento inicial.
√Årboles de Decisi√≥n ‚Üí Para capturar relaciones no lineales en los datos.
Random Forest ‚Üí Modelo basado en ensambles para mejorar la predicci√≥n.
Gradient Boosting (XGBoost, LightGBM) ‚Üí Modelos avanzados para optimizaci√≥n de predicciones.
Se realiz√≥ tuneo de hiperpar√°metros mediante Grid Search y Random Search para mejorar la precisi√≥n del modelo.

# üéØ 4. Evaluaci√≥n del Modelo
Comparaci√≥n de modelos utilizando m√©tricas clave:
F1-score ‚Üí M√©trica principal para evaluar la clasificaci√≥n.
AUC-ROC ‚Üí Para medir la capacidad de diferenciaci√≥n del modelo.
Precisi√≥n y Recall ‚Üí Evaluaci√≥n del equilibrio entre falsos positivos y negativos.
Matriz de confusi√≥n para visualizar errores de clasificaci√≥n.

# üìö Librer√≠as Utilizadas
Para la implementaci√≥n del modelo, se usaron las siguientes librer√≠as en Python:

Pandas / NumPy ‚Üí Manipulaci√≥n y an√°lisis de datos.
Matplotlib / Seaborn ‚Üí Visualizaci√≥n de datos.
Scikit-learn ‚Üí Modelos de clasificaci√≥n, m√©tricas y optimizaci√≥n.
Imbalanced-learn ‚Üí Manejo del desbalance de clases con SMOTE.
XGBoost / LightGBM ‚Üí Algoritmos avanzados de boosting para mejorar la clasificaci√≥n.

# üìà Resultados y Conclusi√≥n
El modelo de Gradient Boosting (XGBoost) logr√≥ el mejor rendimiento, alcanzando un F1-score alto y un AUC-ROC superior a 0.85, lo que indica una excelente capacidad de predicci√≥n.
Las variables m√°s influyentes en la predicci√≥n de cancelaci√≥n fueron:
Frecuencia de uso del servicio.
M√©todo de pago utilizado.
Tiempo desde el √∫ltimo viaje.
N√∫mero de viajes realizados en los √∫ltimos meses.
El manejo del desbalance de clases con SMOTE mejor√≥ la capacidad predictiva del modelo, reduciendo falsos negativos.
Se recomienda implementar estrategias de retenci√≥n para los clientes con alta probabilidad de cancelar, como programas de fidelizaci√≥n o descuentos personalizados.
