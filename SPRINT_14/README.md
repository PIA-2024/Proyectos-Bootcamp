# üé¨ Clasificaci√≥n de Rese√±as de Pel√≠culas con Machine Learning

# üìñ Resumen del Proyecto
Este proyecto tiene como objetivo clasificar autom√°ticamente rese√±as de pel√≠culas en positivas o negativas utilizando modelos de machine learning y procesamiento de lenguaje natural (NLP).

Se entrenaron distintos modelos para analizar el sentimiento de los textos y determinar la mejor estrategia para predecir correctamente si una rese√±a es favorable o desfavorable.

El principal criterio de evaluaci√≥n es la m√©trica F1-score, con un objetivo m√≠nimo de 0.85.

# üõ† Metodolog√≠a Utilizada

Para lograr la clasificaci√≥n de rese√±as de pel√≠culas, se sigui√≥ el siguiente proceso:

# üîç 1. Exploraci√≥n y Preparaci√≥n de Datos
Carga del dataset de rese√±as de pel√≠culas de IMDb.
Revisi√≥n de estructura del dataset y distribuci√≥n de clases.
An√°lisis de valores nulos y eliminaci√≥n de datos innecesarios.
An√°lisis de la cantidad de palabras en cada rese√±a y su impacto en la clasificaci√≥n.

# üèóÔ∏è 2. Preprocesamiento de Texto
Para transformar los textos en datos utilizables por los modelos de machine learning, se aplicaron t√©cnicas de Procesamiento de Lenguaje Natural (NLP), tales como:

Conversi√≥n del texto a min√∫sculas.
Eliminaci√≥n de caracteres especiales y puntuaci√≥n.
Tokenizaci√≥n y eliminaci√≥n de stopwords (palabras irrelevantes como "el", "de", "y").
Lematizaci√≥n para reducir palabras a su forma base.
Representaci√≥n num√©rica de los textos mediante:
TF-IDF (Term Frequency - Inverse Document Frequency)
Embeddings de palabras (Word2Vec, GloVe, BERT - en pruebas avanzadas)

# ü§ñ 3. Entrenamiento de Modelos de Machine Learning
Se probaron distintos algoritmos de clasificaci√≥n para identificar el m√°s preciso:

Regresi√≥n Log√≠stica ‚Üí Modelo base para evaluar desempe√±o inicial.
Na√Øve Bayes ‚Üí Modelo probabil√≠stico efectivo para NLP.
Random Forest ‚Üí Modelo basado en √°rboles de decisi√≥n para mejorar la clasificaci√≥n.
Gradient Boosting (XGBoost, LightGBM) ‚Üí Modelos avanzados para optimizaci√≥n de predicciones.
Redes Neuronales con Embeddings (BERT - Prueba Opcional) ‚Üí Para capturar significado contextual en textos largos.

# üéØ 4. Evaluaci√≥n del Modelo
Comparaci√≥n de modelos utilizando m√©tricas como Precisi√≥n, Recall y F1-score.
C√°lculo de la matriz de confusi√≥n para analizar errores en la clasificaci√≥n.
Optimizaci√≥n de hiperpar√°metros mediante Grid Search y Random Search.
An√°lisis de las palabras m√°s influyentes en las predicciones del modelo.

# üìö Librer√≠as Utilizadas
Para la implementaci√≥n del proyecto, se usaron diversas librer√≠as en Python, incluyendo:

Pandas / NumPy ‚Üí Manipulaci√≥n y an√°lisis de datos.
Matplotlib / Seaborn ‚Üí Visualizaci√≥n de datos.
Scikit-learn ‚Üí Modelos de machine learning y m√©tricas de evaluaci√≥n.
NLTK / SpaCy ‚Üí Procesamiento de lenguaje natural.
TF-IDF / Word2Vec / BERT ‚Üí M√©todos de vectorizaci√≥n de texto.

# üìà Resultados y Conclusi√≥n
El modelo de Regresi√≥n Log√≠stica con TF-IDF obtuvo el mejor equilibrio entre precisi√≥n y velocidad, logrando un F1-score de 0.87, superando el objetivo del proyecto.
Na√Øve Bayes tambi√©n mostr√≥ buen desempe√±o, pero con menor precisi√≥n en ciertas rese√±as con lenguaje m√°s ambiguo.
Los modelos basados en embeddings (BERT) mejoraron la comprensi√≥n de contexto, pero fueron m√°s costosos computacionalmente.
Las palabras m√°s relevantes en la clasificaci√≥n de rese√±as negativas inclu√≠an t√©rminos como "aburrida", "decepcionante", "mala", mientras que en rese√±as positivas destacaban "excelente", "fascinante", "maravillosa".
Se recomienda seguir optimizando los modelos con embeddings preentrenados y t√©cnicas de transferencia de aprendizaje para mejorar la clasificaci√≥n en rese√±as con iron√≠a o lenguaje subjetivo.

