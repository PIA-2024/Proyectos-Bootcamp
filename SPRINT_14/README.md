# üé¨ Clasificaci√≥n de Rese√±as de Pel√≠culas con Machine Learning

# üìñ Resumen del Proyecto
Este proyecto tiene como objetivo clasificar autom√°ticamente rese√±as de pel√≠culas en positivas o negativas utilizando modelos de Machine Learning y t√©cnicas de Procesamiento de Lenguaje Natural (NLP). Se entrenaron distintos modelos para analizar el sentimiento de los textos y determinar la mejor estrategia para predecir correctamente si una rese√±a es favorable o desfavorable. El principal criterio de evaluaci√≥n es la m√©trica F1-score, con un objetivo m√≠nimo de 0.85.

# üõ† Metodolog√≠a Utilizada
Para lograr la clasificaci√≥n de rese√±as de pel√≠culas, se sigui√≥ el siguiente proceso:

# üîç 1. Exploraci√≥n y Preparaci√≥n de Datos
Carga del Dataset: Se utiliz√≥ el conjunto de datos de rese√±as de pel√≠culas de IMDb, que contiene textos de rese√±as junto con su clasificaci√≥n como positivas o negativas.
Revisi√≥n de la Estructura del Dataset: An√°lisis de la cantidad de rese√±as, distribuci√≥n de clases y verificaci√≥n de la presencia de valores nulos o datos faltantes.
An√°lisis de la Longitud de las Rese√±as: Estudio de la cantidad de palabras en cada rese√±a y su impacto en la clasificaci√≥n.

# üèóÔ∏è 2. Preprocesamiento de Texto
Para transformar los textos en datos utilizables por los modelos de machine learning, se aplicaron t√©cnicas de NLP, tales como:

Limpieza del Texto: Conversi√≥n del texto a min√∫sculas, eliminaci√≥n de caracteres especiales, puntuaci√≥n y n√∫meros.
Tokenizaci√≥n: Divisi√≥n del texto en palabras o tokens individuales.
Eliminaci√≥n de Stop Words: Remoci√≥n de palabras comunes que no aportan significado significativo al an√°lisis (e.g., "el", "la", "de").
Lematizaci√≥n/Stemming: Reducci√≥n de las palabras a su forma base o ra√≠z.
Vectorizaci√≥n: Conversi√≥n de los textos preprocesados en representaciones num√©ricas utilizando t√©cnicas como TF-IDF (Term Frequency-Inverse Document Frequency).

# ü§ñ 3. Entrenamiento de Modelos de Machine Learning
Se probaron distintos modelos de clasificaci√≥n para determinar cu√°l ofrec√≠a el mejor rendimiento:

Regresi√≥n Log√≠stica: Modelo base para evaluar el rendimiento inicial.
M√°quinas de Soporte Vectorial (SVM): Para capturar relaciones complejas en los datos.
√Årboles de Decisi√≥n y Random Forest: Modelos basados en ensambles para mejorar la predicci√≥n.
Naive Bayes: Modelo probabil√≠stico com√∫nmente utilizado en clasificaci√≥n de texto.
Se realiz√≥ ajuste de hiperpar√°metros mediante Grid Search para optimizar el rendimiento de los modelos.

# üéØ 4. Evaluaci√≥n del Modelo
M√©tricas de Evaluaci√≥n: Se utilizaron m√©tricas como F1-score, Precisi√≥n, Recall y Exactitud para evaluar el rendimiento de los modelos.
Matriz de Confusi√≥n: Para analizar los verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos.
Validaci√≥n Cruzada: Para asegurar la generalizaci√≥n del modelo y evitar sobreajuste.

# üìö Librer√≠as Utilizadas
Para la implementaci√≥n del proyecto, se utilizaron las siguientes librer√≠as en Python:

Pandas / NumPy: Manipulaci√≥n y an√°lisis de datos.
NLTK / SpaCy: Herramientas para procesamiento de lenguaje natural.
Scikit-learn: Modelos de clasificaci√≥n, m√©tricas y herramientas de preprocesamiento.
Matplotlib / Seaborn: Visualizaci√≥n de datos y resultados.

# üìà Resultados y Conclusi√≥n
Mejor Modelo: El modelo de M√°quinas de Soporte Vectorial (SVM) con kernel lineal alcanz√≥ un F1-score de 0.87, superando el objetivo establecido de 0.85.
Caracter√≠sticas Relevantes: Las palabras con mayor peso en la clasificaci√≥n fueron t√©rminos claramente asociados con sentimientos positivos o negativos, lo que indica que el modelo captur√≥ adecuadamente el sentimiento de las rese√±as.

Conclusi√≥n: El modelo desarrollado es efectivo para clasificar autom√°ticamente rese√±as de pel√≠culas en positivas o negativas, y puede ser implementado en sistemas de recomendaci√≥n o an√°lisis de opini√≥n para mejorar la experiencia del usuario.
